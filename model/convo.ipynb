{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import numpy\\nfrom tensorflow.examples.tutorials.mnist import input_data\\n\\nfrom keras.models import Sequential\\nfrom keras.layers import Dense\\nfrom keras.layers import Dropout\\nfrom keras.layers import Flatten\\nfrom keras.layers.convolutional import Conv2D\\nfrom keras.layers.convolutional import MaxPooling2D\\nfrom keras.utils import np_utils\\nfrom keras import backend as K\\nK.set_image_dim_ordering(\\'th\\')\\n# fix random seed for reproducibility\\nseed = 7\\nnumpy.random.seed(seed)\\n\\nmnist  = input_data.read_data_sets(\"MNIST_data\" , one_hot = True)\\n\\n\\nX_train =mnist.train.images\\nY_train= mnist.train.labels\\n\\n\\n#follows the same above naming convention where X and y are testing numpy arrays\\n\\nX_test = mnist.test.images\\nY_test = mnist.test.labels\\nprint(X_train.shape)\\n\\n# reshape to be [samples][pixels][width][height]\\nX_train = X_train.reshape(X_train.shape[0],1, 28, 28).astype(\\'float32\\')\\nX_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype(\\'float32\\')\\n\\n\\n\\n# one hot encode outputs\\ny_train = np_utils.to_categorical(Y_train)\\ny_test = np_utils.to_categorical(Y_test)\\n\\n\\nnum_classes = y_test.shape[1]\\n\\n\\n# create model\\nmodel = Sequential()\\nmodel.add(Conv2D(30, (5, 5), input_shape=(1, 28, 28,), activation=\\'relu\\'))\\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\\nmodel.add(Conv2D(15, (3, 3), activation=\\'relu\\'))\\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\\nmodel.add(Dropout(0.2))\\nmodel.add(Flatten())\\nmodel.add(Dense(128, activation=\\'relu\\'))\\nmodel.add(Dense(50, activation=\\'relu\\'))\\nmodel.add(Dense(10, activation=\\'softmax\\'))\\n\\n# Compile model\\n\\nmodel.compile(loss=\\'categorical_crossentropy\\', optimizer=\\'adam\\', metrics=[\\'accuracy\\'])\\n\\nprint(y_train.shape)'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import numpy\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "mnist  = input_data.read_data_sets(\"MNIST_data\" , one_hot = True)\n",
    "\n",
    "\n",
    "X_train =mnist.train.images\n",
    "Y_train= mnist.train.labels\n",
    "\n",
    "\n",
    "#follows the same above naming convention where X and y are testing numpy arrays\n",
    "\n",
    "X_test = mnist.test.images\n",
    "Y_test = mnist.test.labels\n",
    "print(X_train.shape)\n",
    "\n",
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0],1, 28, 28).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')\n",
    "\n",
    "\n",
    "\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(Y_train)\n",
    "y_test = np_utils.to_categorical(Y_test)\n",
    "\n",
    "\n",
    "num_classes = y_test.shape[1]\n",
    "\n",
    "\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(30, (5, 5), input_shape=(1, 28, 28,), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(15, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print(y_train.shape)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(X_train, y_train, epochs = 10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')\n",
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]\n",
    "\n",
    "# define the larger model\n",
    "def larger_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(30, (5, 5), input_shape=(1, 28, 28), activation='relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\tmodel.add(Conv2D(15, (3, 3), activation='relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu'))\n",
    "\tmodel.add(Dense(50, activation='relu'))\n",
    "\tmodel.add(Dense(num_classes, activation='softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.1902 - acc: 0.9405 - val_loss: 0.0530 - val_acc: 0.9823\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 0.0682 - acc: 0.9789 - val_loss: 0.0411 - val_acc: 0.9870\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 0.0528 - acc: 0.9838 - val_loss: 0.0336 - val_acc: 0.9883\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 9s 155us/step - loss: 0.0434 - acc: 0.9863 - val_loss: 0.0325 - val_acc: 0.9888\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.0364 - acc: 0.9884 - val_loss: 0.0294 - val_acc: 0.9906\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.0332 - acc: 0.9894 - val_loss: 0.0246 - val_acc: 0.9923\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.0290 - acc: 0.9904 - val_loss: 0.0259 - val_acc: 0.9925\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.0269 - acc: 0.9912 - val_loss: 0.0271 - val_acc: 0.9916\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.0218 - acc: 0.9931 - val_loss: 0.0302 - val_acc: 0.9911\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.0209 - acc: 0.9935 - val_loss: 0.0241 - val_acc: 0.9921\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.0200 - acc: 0.9935 - val_loss: 0.0293 - val_acc: 0.9918\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.0184 - acc: 0.9940 - val_loss: 0.0236 - val_acc: 0.9937\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 9s 155us/step - loss: 0.0189 - acc: 0.9936 - val_loss: 0.0260 - val_acc: 0.9924\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 9s 153us/step - loss: 0.0176 - acc: 0.9945 - val_loss: 0.0326 - val_acc: 0.9906\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.0170 - acc: 0.9949 - val_loss: 0.0294 - val_acc: 0.9922\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.0156 - acc: 0.9950 - val_loss: 0.0269 - val_acc: 0.9932\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 9s 155us/step - loss: 0.0146 - acc: 0.9956 - val_loss: 0.0273 - val_acc: 0.9924\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.0151 - acc: 0.9950 - val_loss: 0.0275 - val_acc: 0.9926\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.0139 - acc: 0.9956 - val_loss: 0.0314 - val_acc: 0.9916\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.0149 - acc: 0.9950 - val_loss: 0.0290 - val_acc: 0.9927\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.0132 - acc: 0.9959 - val_loss: 0.0260 - val_acc: 0.9937\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.0137 - acc: 0.9958 - val_loss: 0.0250 - val_acc: 0.9921\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.0116 - acc: 0.9965 - val_loss: 0.0280 - val_acc: 0.9924\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 9s 155us/step - loss: 0.0120 - acc: 0.9963 - val_loss: 0.0285 - val_acc: 0.9923\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.0122 - acc: 0.9964 - val_loss: 0.0308 - val_acc: 0.9925\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.0104 - acc: 0.9966 - val_loss: 0.0346 - val_acc: 0.9914\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.0123 - acc: 0.9961 - val_loss: 0.0316 - val_acc: 0.9924\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 9s 155us/step - loss: 0.0109 - acc: 0.9967 - val_loss: 0.0270 - val_acc: 0.9939\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.0110 - acc: 0.9963 - val_loss: 0.0481 - val_acc: 0.9894\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.0106 - acc: 0.9965 - val_loss: 0.0350 - val_acc: 0.9923\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ecc8115a90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = larger_model()\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('mymodel2_cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1, 28, 28)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
